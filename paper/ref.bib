@ARTICLE{8509143,
  author={Alzhouri, Fadi and Agarwal, Anjali and Liu, Yan},
  journal={IEEE Transactions on Cloud Computing}, 
  title={Maximizing Cloud Revenue using Dynamic Pricing of Multiple Class Virtual Machines}, 
  year={2021},
  volume={9},
  number={2},
  pages={682-695},
  doi={10.1109/TCC.2018.2878023}}
@article{Mnih2015,
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and others},
  title = {Human-level control through deep reinforcement learning},
  journal = {Nature},
  volume = {518},
  pages = {529-533},
  year = {2015},
  doi = {10.1038/nature14236},
  publisher = {Nature Publishing Group}
}
@misc{schulman2017proximal,
      title={Proximal Policy Optimization Algorithms}, 
      author={John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
      year={2017},
      eprint={1707.06347},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@article{ZHANG2022108663,
title = {Online routing and spectrum allocation in elastic optical networks based on dueling Deep Q-network},
journal = {Computers & Industrial Engineering},
volume = {173},
pages = {108663},
year = {2022},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2022.108663},
url = {https://www.sciencedirect.com/science/article/pii/S0360835222006519},
author = {Jiawei Zhang and Fengchen Qian and Junqiang Yang},
keywords = {Online routing and spectrum allocation, Elastic optical networks, Mixed-integer linear program, Markov decision process, Deep reinforcement learning, Deep Q-network},
abstract = {The study of online routing and spectrum allocation (RSA) problem has assumed increasing importance due to the exponential growth of dynamic traffic with uncertainty in elastic optical networks (EONs). This paper first formulates offline RSA as a mixed-integer linear program (MILP) with the consideration of the time attribute, and then models online RSA by a carefully designed Markov decision process (MDP), including the state, action and reward. To deal with such a complex dynamic optimization problem, a novel algorithm based on the classic deep reinforcement learning (DRL) framework, Deep Q-network (DQN), is developed. For further promoting the training efficiency, a dueling network architecture, an improved É›-greedy strategy and a series of parameter adjustments are applied. Simulation results demonstrate the effectiveness of the proposed algorithm and show its superiority in reducing the blocking probability compared with the state of the art, which further exhibits the potential of applying DRL to solve such complex real-time decision-making problems.}
}